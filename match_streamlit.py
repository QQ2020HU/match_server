import streamlit as st
import os
import io
import fitz  # PyMuPDF
import numpy as np
import faiss
from PIL import Image
import pickle
import time
import torch
import torchvision.transforms as transforms
from transformers import AutoImageProcessor, AutoModel
import shutil
import tempfile
from tqdm import tqdm
import base64
import matplotlib.pyplot as plt
import gc

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="PDFå›¾åƒæœç´¢å¼•æ“",
    page_icon=":mag:",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
import warnings
warnings.filterwarnings("ignore")

# æ¨¡å‹ç¼“å­˜è·¯å¾„
MODEL_CACHE = "./model_cache"
os.makedirs(MODEL_CACHE, exist_ok=True)

class DINOV2FeatureExtractor:
    def __init__(self, model_size="small"):
        """
        åˆå§‹åŒ–DINOv2ç‰¹å¾æå–å™¨
        """
        self.device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
        model_name = {
            "small": "/Users/qiangqianghu/Projects/huggingface_models_bin/dinov2_small",
            "base": "/Users/qiangqianghu/Projects/huggingface_models_bin/dinov2_base",
            "large": "facebook/dinov2-large",
            "giant": "facebook/dinov2-giant"
        }[model_size]
        
        st.info(f"åŠ è½½DINOv2æ¨¡å‹: {model_name}...")
        start_time = time.time()
        
        # ä½¿ç”¨æœ¬åœ°ç¼“å­˜
        self.processor = AutoImageProcessor.from_pretrained(model_name, use_fast=True)
        # macOS ä¸Šä½¿ç”¨ MPS åŠ é€Ÿï¼ˆApple Siliconï¼‰
        if torch.backends.mps.is_available():
            print("ä½¿ç”¨ Apple MPS åŠ é€Ÿ")
            self.model = AutoModel.from_pretrained(model_name).to(self.device)
        else:
            print("ä½¿ç”¨ CPU")
            self.model = AutoModel.from_pretrained(model_name)
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼   
        self.model.eval()
        
        # åˆ›å»ºå›¾åƒé¢„å¤„ç†æµç¨‹
        self.transform = transforms.Compose([
            transforms.Resize((518, 518)),  # DINOv2çš„è¾“å…¥å°ºå¯¸
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                 std=[0.229, 0.224, 0.225])
        ])
        
        st.success(f"æ¨¡å‹åŠ è½½å®Œæˆ! è€—æ—¶: {time.time()-start_time:.2f}ç§’")

    def extract_features(self, img):
        """ä½¿ç”¨DINOv2æå–å›¾åƒç‰¹å¾"""
        try:
            # é¢„å¤„ç†å›¾åƒ
            img = self.transform(img).unsqueeze(0).to(self.device)
            
            # æå–ç‰¹å¾
            with torch.no_grad():
                outputs = self.model(img)
            
            # è·å–[CLS]æ ‡è®°çš„ç‰¹å¾
            features = outputs.last_hidden_state[:, 0].cpu().numpy()
            
            # å½’ä¸€åŒ–ç‰¹å¾å‘é‡
            features = features / np.linalg.norm(features)
            
            return features.astype('float32').flatten()
        
        except Exception as e:
            st.error(f"ç‰¹å¾æå–é”™è¯¯: {str(e)}")
            return np.zeros(self.model.config.hidden_size, dtype='float32')

class PDFImageSearcher:
    def __init__(self, index_path="dino_pdf_index.index", metadata_path="dino_metadata.pkl", model_size="small"):
        self.index_path = index_path
        self.metadata_path = metadata_path
        self.index = None
        self.metadata = []
        self.feature_extractor = DINOV2FeatureExtractor(model_size)
        self.feature_dim = self.feature_extractor.model.config.hidden_size
        self.model_size = model_size
        self.index_loaded = False
    
    def build_index(self, pdf_directory):
        """æ„å»ºPDFå›¾åƒç´¢å¼•"""
        st.info(f"å¼€å§‹æ„å»ºPDFå›¾åƒç´¢å¼•ï¼Œç›®å½•: {pdf_directory}")
        st.info(f"ä½¿ç”¨ç‰¹å¾ç»´åº¦: {self.feature_dim}")
        
        # è·å–æ‰€æœ‰PDFæ–‡ä»¶
        pdf_files = [f for f in os.listdir(pdf_directory) if f.lower().endswith('.pdf')]
        if not pdf_files:
            st.warning("æœªæ‰¾åˆ°PDFæ–‡ä»¶")
            return
        
        # å‡†å¤‡FAISSç´¢å¼• - ä½¿ç”¨å†…ç§¯è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        self.index = faiss.IndexFlatIP(self.feature_dim)
        self.metadata = []
        
        total_images = 0
        start_time = time.time()
        
        # è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # éå†æ‰€æœ‰PDFæ–‡ä»¶
        for idx, pdf_file in enumerate(pdf_files):
            pdf_path = os.path.join(pdf_directory, pdf_file)
            
            try:
                status_text.text(f"å¤„ç†æ–‡ä»¶ä¸­: {pdf_file} ({idx+1}/{len(pdf_files)})")
                doc = fitz.open(pdf_path)
                # éå†æ‰€æœ‰é¡µé¢
                for page_num in range(len(doc)):
                    page = doc.load_page(page_num)
                    img_list = page.get_images(full=True)
                    
                    # å¤„ç†é¡µé¢ä¸­çš„æ¯å¼ å›¾ç‰‡
                    for img_index, img_info in enumerate(img_list):
                        xref = img_info[0]
                        base_img = doc.extract_image(xref)
                        img_bytes = base_img["image"]
                        
                        # è½¬æ¢ä¸ºPILå›¾åƒ
                        try:
                            img = Image.open(io.BytesIO(img_bytes))
                            # è½¬æ¢ä¸ºRGBæ ¼å¼
                            if img.mode != 'RGB':
                                img = img.convert('RGB')
                                
                            # è°ƒæ•´å¤§å›¾åƒå°ºå¯¸ï¼ˆé¿å…å†…å­˜é—®é¢˜ï¼‰
                            if max(img.size) > 2000:
                                ratio = 2000 / max(img.size)
                                new_size = (int(img.width * ratio), int(img.height * ratio))
                                img = img.resize(new_size, Image.LANCZOS)
                                
                            # ä½¿ç”¨DINOv2æå–ç‰¹å¾
                            features = self.feature_extractor.extract_features(img)
                            
                            # æ·»åŠ åˆ°ç´¢å¼•
                            self.index.add(np.array([features]))
                            
                            # å­˜å‚¨å…ƒæ•°æ®
                            self.metadata.append({
                                "book": pdf_file,
                                "page": page_num + 1,
                                "img_index": img_index,
                                "dimensions": img.size,
                                "image_bytes": img_bytes  # å­˜å‚¨åŸå§‹å›¾åƒå­—èŠ‚
                            })
                            
                            total_images += 1
                        except Exception as e:
                            st.warning(f"å¤„ç†å›¾åƒæ—¶å‡ºé”™ {pdf_file} ç¬¬ {page_num+1} é¡µ: {str(e)}")
                
                doc.close()
                progress_bar.progress((idx + 1) / len(pdf_files))
                # å®šæœŸæ¸…ç†å†…å­˜
                if total_images % 10 == 0:
                    gc.collect()
                    if torch.backends.mps.is_available():
                        torch.mps.empty_cache()
                        
            except Exception as e:
                st.error(f"æ‰“å¼€PDFæ—¶å‡ºé”™ {pdf_file}: {str(e)}")
        
        # ä¿å­˜ç´¢å¼•å’Œå…ƒæ•°æ®
        if total_images > 0:
            faiss.write_index(self.index, self.index_path)
            with open(self.metadata_path, "wb") as f:
                pickle.dump(self.metadata, f)
            st.success(f"ç´¢å¼•æ„å»ºå®Œæˆ! å…±å¤„ç† {len(pdf_files)} æœ¬PDF, {total_images} å¼ å›¾ç‰‡")
            st.success(f"è€—æ—¶: {time.time()-start_time:.2f}ç§’")
            self.index_loaded = True
        else:
            st.warning("æœªæ‰¾åˆ°å¯å¤„ç†çš„å›¾åƒ")
            self.index = None
            
        # æ¸…ç†å†…å­˜
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    def load_index(self):
        """åŠ è½½é¢„æ„å»ºçš„ç´¢å¼•"""
        if os.path.exists(self.index_path) and os.path.exists(self.metadata_path):
            st.info("åŠ è½½ç´¢å¼•æ–‡ä»¶...")
            self.index = faiss.read_index(self.index_path)
            with open(self.metadata_path, "rb") as f:
                self.metadata = pickle.load(f)
            st.success(f"ç´¢å¼•åŠ è½½æˆåŠŸ! å…± {len(self.metadata)} å¼ å›¾ç‰‡")
            self.index_loaded = True
            return True
        else:
            st.warning("æœªæ‰¾åˆ°ç´¢å¼•æ–‡ä»¶ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•")
            return False

    def search_image(self, image, top_k=5, similarity_threshold=70.0):
        """æœç´¢ç›¸ä¼¼å›¾ç‰‡"""
        if not self.index_loaded:
            if not self.load_index():
                return []
        
        try:
            # è½¬æ¢å›¾åƒ
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # æå–ç‰¹å¾
            target_features = self.feature_extractor.extract_features(image)
            
            # åœ¨ç´¢å¼•ä¸­æœç´¢
            similarities, indices = self.index.search(
                np.array([target_features]).astype('float32'), 
                top_k
            )
            
            # å‡†å¤‡ç»“æœ
            results = []
            for i, idx in enumerate(indices[0]):
                if idx < 0 or idx >= len(self.metadata):
                    continue
                
                match = self.metadata[idx]
                # ä½™å¼¦ç›¸ä¼¼åº¦ = å†…ç§¯ï¼ˆå› ä¸ºç‰¹å¾å‘é‡å·²å½’ä¸€åŒ–ï¼‰
                cosine_similarity = float(similarities[0][i])
                
                # è½¬æ¢ä¸ºç™¾åˆ†æ¯”ç›¸ä¼¼åº¦ (0-100%)
                similarity_percent = max(0.0, min(100.0, cosine_similarity * 100))
                
                if similarity_percent >= similarity_threshold:
                    # ä»å­—èŠ‚åˆ›å»ºå›¾åƒ
                    match_image = Image.open(io.BytesIO(match["image_bytes"]))
                    
                    results.append({
                        "book": match["book"],
                        "page": match["page"],
                        "similarity": similarity_percent,
                        "dimensions": match["dimensions"],
                        "image": match_image
                    })
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            results.sort(key=lambda x: x["similarity"], reverse=True)
            
            return results
        except Exception as e:
            st.error(f"æœç´¢æ—¶å‡ºé”™: {str(e)}")
            return []

# åº”ç”¨ä¸»å‡½æ•°
def main():
    # æ ‡é¢˜
    st.title("ğŸ“š PDFå›¾åƒæœç´¢å¼•æ“")
    st.markdown("ä½¿ç”¨DINOv2æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨PDFåº“ä¸­æœç´¢ç›¸ä¼¼å›¾åƒ")
    
    # åˆå§‹åŒ–çŠ¶æ€
    if 'searcher' not in st.session_state:
        st.session_state.searcher = PDFImageSearcher()
    
    # ä¾§è¾¹æ  - ç´¢å¼•ç®¡ç†
    with st.sidebar:
        st.header("ç´¢å¼•ç®¡ç†")
        
        # æ¨¡å‹é€‰æ‹©
        model_size = st.selectbox(
            "é€‰æ‹©DINOv2æ¨¡å‹å°ºå¯¸",
            ("small", "base", "large", "giant"),
            index=0,
            help="small: é€Ÿåº¦å¿«ä½†ç²¾åº¦è¾ƒä½, giant: ç²¾åº¦é«˜ä½†é€Ÿåº¦æ…¢"
        )
        
        # æ›´æ–°æ¨¡å‹
        if st.button("é‡æ–°åŠ è½½æ¨¡å‹"):
            st.session_state.searcher = PDFImageSearcher(model_size=model_size)
            st.success("æ¨¡å‹å·²é‡æ–°åŠ è½½!")
        
        # æ–‡ä»¶ä¸Šä¼ 
        st.subheader("åˆ›å»ºæ–°ç´¢å¼•")
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ PDFæ–‡ä»¶", 
            type="pdf", 
            accept_multiple_files=True,
            help="é€‰æ‹©è¦æ·»åŠ åˆ°ç´¢å¼•çš„PDFæ–‡ä»¶"
        )
        
        # æ„å»ºç´¢å¼•
        if uploaded_files and st.button("æ„å»ºç´¢å¼•"):
            with st.spinner("æ­£åœ¨å¤„ç†PDFæ–‡ä»¶..."):
                # åˆ›å»ºä¸´æ—¶ç›®å½•
                temp_dir = tempfile.mkdtemp()
                
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                for uploaded_file in uploaded_files:
                    file_path = os.path.join(temp_dir, uploaded_file.name)
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                
                # æ„å»ºç´¢å¼•
                st.session_state.searcher = PDFImageSearcher(model_size=model_size)
                st.session_state.searcher.build_index(temp_dir)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                shutil.rmtree(temp_dir)
        
        # ç´¢å¼•çŠ¶æ€
        st.subheader("ç´¢å¼•ä¿¡æ¯")
        if st.session_state.searcher.index_loaded:
            st.success("ç´¢å¼•å·²åŠ è½½")
            st.info(f"å›¾ç‰‡æ•°é‡: {len(st.session_state.searcher.metadata)}")
            st.info(f"æ¨¡å‹å°ºå¯¸: {st.session_state.searcher.model_size}")
        else:
            st.warning("æœªåŠ è½½ç´¢å¼•")
        
        # ç¤ºä¾‹å›¾ç‰‡
        st.subheader("ä½¿ç”¨ç¤ºä¾‹")
        st.image("https://images.unsplash.com/photo-1507842217343-583bb7270b66?auto=format&fit=crop&w=300", 
                 caption="ç¤ºä¾‹å›¾ç‰‡", use_container_width=True)
        st.markdown("ä¸Šä¼ ç±»ä¼¼å›¾ç‰‡è¿›è¡Œæœç´¢")
        
        # é‡ç½®æŒ‰é’®
        if st.button("é‡ç½®åº”ç”¨"):
            st.session_state.clear()
            st.experimental_rerun()
    
    # ä¸»å†…å®¹åŒº - å›¾ç‰‡æœç´¢
    st.header("å›¾åƒæœç´¢")
    
    # å›¾ç‰‡ä¸Šä¼ 
    col1, col2 = st.columns([1, 2])
    with col1:
        uploaded_image = st.file_uploader(
            "ä¸Šä¼ æœç´¢å›¾ç‰‡", 
            type=["jpg", "jpeg", "png"],
            help="ä¸Šä¼ è¦åœ¨PDFåº“ä¸­æœç´¢çš„å›¾ç‰‡"
        )
        
        # æœç´¢å‚æ•°
        top_k = st.slider("è¿”å›ç»“æœæ•°é‡", 1, 20, 5)
        similarity_threshold = st.slider("ç›¸ä¼¼åº¦é˜ˆå€¼ (%)", 0, 100, 70)
        
        # æœç´¢æŒ‰é’®
        if st.button("å¼€å§‹æœç´¢", disabled=not st.session_state.searcher.index_loaded):
            if uploaded_image:
                with st.spinner("æ­£åœ¨æœç´¢..."):
                    try:
                        image = Image.open(uploaded_image)
                        st.session_state.results = st.session_state.searcher.search_image(
                            image, 
                            top_k=top_k,
                            similarity_threshold=similarity_threshold
                        )
                    except Exception as e:
                        st.error(f"å›¾ç‰‡å¤„ç†é”™è¯¯: {str(e)}")
            else:
                st.warning("è¯·å…ˆä¸Šä¼ å›¾ç‰‡")
    
    with col2:
        if uploaded_image:
            st.image(uploaded_image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)
        else:
            st.info("è¯·ä¸Šä¼ æœç´¢å›¾ç‰‡")
    
    # æ˜¾ç¤ºç»“æœ
    if 'results' in st.session_state and st.session_state.results:
        st.header("æœç´¢ç»“æœ")
        st.success(f"æ‰¾åˆ° {len(st.session_state.results)} ä¸ªåŒ¹é…ç»“æœ")
        
        # æ˜¾ç¤ºç»“æœç½‘æ ¼
        cols = st.columns(min(3, len(st.session_state.results)))
        
        for idx, result in enumerate(st.session_state.results):
            col = cols[idx % len(cols)]
            
            with col:
                st.image(
                    result["image"], 
                    caption=f"ç›¸ä¼¼åº¦: {result['similarity']:.2f}%",
                    use_container_width=True
                )
                
                st.markdown(f"**ç”µå­ä¹¦**: `{result['book']}`")
                st.markdown(f"**é¡µç **: {result['page']}")
                st.markdown(f"**åŸå§‹å°ºå¯¸**: {result['dimensions'][0]}Ã—{result['dimensions'][1]}")
                
                # æ·»åŠ ä¸‹è½½æŒ‰é’®
                buffered = io.BytesIO()
                result["image"].save(buffered, format="JPEG")
                img_str = base64.b64encode(buffered.getvalue()).decode()
                href = f'<a href="data:image/jpeg;base64,{img_str}" download="match_{idx+1}.jpg">ä¸‹è½½å›¾ç‰‡</a>'
                st.markdown(href, unsafe_allow_html=True)
                
                st.divider()
    elif 'results' in st.session_state:
        st.warning("æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")

# è¿è¡Œåº”ç”¨
if __name__ == "__main__":
    main()